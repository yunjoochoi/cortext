"""SAR head for text recognition.

Vendored from PaddleOCR ppocr/modeling/heads/rec_sar_head.py.
"""

import paddle
from paddle import ParamAttr
import paddle.nn as nn
import paddle.nn.functional as F


class SAREncoder(nn.Layer):
    def __init__(self, enc_bi_rnn=False, enc_drop_rnn=0.1, enc_gru=False,
                 d_model=512, d_enc=512, mask=True, **kwargs):
        super().__init__()
        self.enc_bi_rnn = enc_bi_rnn
        self.mask = mask
        direction = "bidirectional" if enc_bi_rnn else "forward"
        rnn_kwargs = dict(input_size=d_model, hidden_size=d_enc, num_layers=2,
                          time_major=False, dropout=enc_drop_rnn, direction=direction)
        self.rnn_encoder = nn.GRU(**rnn_kwargs) if enc_gru else nn.LSTM(**rnn_kwargs)
        encoder_rnn_out_size = d_enc * (int(enc_bi_rnn) + 1)
        self.linear = nn.Linear(encoder_rnn_out_size, encoder_rnn_out_size)

    def forward(self, feat, img_metas=None):
        valid_ratios = None
        if img_metas is not None and self.mask:
            valid_ratios = img_metas[-1]
        h_feat = feat.shape[2]
        feat_v = F.max_pool2d(feat, kernel_size=(h_feat, 1), stride=1, padding=0)
        feat_v = feat_v.squeeze(2).transpose([0, 2, 1])
        holistic_feat = self.rnn_encoder(feat_v)[0]

        if valid_ratios is not None:
            valid_hf = []
            T = paddle.shape(holistic_feat)[1]
            for i in range(valid_ratios.shape[0]):
                valid_step = paddle.minimum(
                    T, paddle.ceil(valid_ratios[i] * T).astype(T.dtype)) - 1
                valid_hf.append(holistic_feat[i, valid_step, :])
            valid_hf = paddle.stack(valid_hf, axis=0)
        else:
            valid_hf = holistic_feat[:, -1, :]
        return self.linear(valid_hf)


class ParallelSARDecoder(nn.Layer):
    def __init__(self, out_channels, enc_bi_rnn=False, dec_bi_rnn=False,
                 dec_drop_rnn=0.0, dec_gru=False, d_model=512, d_enc=512,
                 d_k=64, pred_dropout=0.1, max_text_length=30, mask=True,
                 pred_concat=True, **kwargs):
        super().__init__()
        self.num_classes = out_channels
        self.enc_bi_rnn = enc_bi_rnn
        self.d_k = d_k
        self.start_idx = out_channels - 2
        self.padding_idx = out_channels - 1
        self.max_seq_len = max_text_length
        self.mask = mask
        self.pred_concat = pred_concat

        encoder_rnn_out_size = d_enc * (int(enc_bi_rnn) + 1)
        decoder_rnn_out_size = encoder_rnn_out_size * (int(dec_bi_rnn) + 1)

        self.conv1x1_1 = nn.Linear(decoder_rnn_out_size, d_k)
        self.conv3x3_1 = nn.Conv2D(d_model, d_k, kernel_size=3, stride=1, padding=1)
        self.conv1x1_2 = nn.Linear(d_k, 1)

        direction = "bidirectional" if dec_bi_rnn else "forward"
        rnn_kwargs = dict(input_size=encoder_rnn_out_size,
                          hidden_size=encoder_rnn_out_size, num_layers=2,
                          time_major=False, dropout=dec_drop_rnn, direction=direction)
        self.rnn_decoder = nn.GRU(**rnn_kwargs) if dec_gru else nn.LSTM(**rnn_kwargs)
        self.embedding = nn.Embedding(
            self.num_classes, encoder_rnn_out_size, padding_idx=self.padding_idx)
        self.pred_dropout = nn.Dropout(pred_dropout)
        pred_num_classes = self.num_classes - 1
        fc_in_channel = (decoder_rnn_out_size + d_model + encoder_rnn_out_size
                         if pred_concat else d_model)
        self.prediction = nn.Linear(fc_in_channel, pred_num_classes)

    def _2d_attention(self, decoder_input, feat, holistic_feat, valid_ratios=None):
        y = self.rnn_decoder(decoder_input)[0]
        attn_query = self.conv1x1_1(y)
        bsz, seq_len, attn_size = attn_query.shape
        attn_query = paddle.unsqueeze(attn_query, axis=[3, 4])
        attn_key = self.conv3x3_1(feat).unsqueeze(1)
        attn_weight = paddle.tanh(paddle.add(attn_key, attn_query))
        attn_weight = self.conv1x1_2(attn_weight.transpose([0, 1, 3, 4, 2]))
        bsz, T, h, w, c = paddle.shape(attn_weight)

        if valid_ratios is not None:
            for i in range(valid_ratios.shape[0]):
                valid_width = paddle.minimum(
                    w.astype("int64"), paddle.ceil(valid_ratios[i] * w).astype("int64"))
                if valid_width < w:
                    attn_weight[i, :, :, valid_width:, :] = float("-inf")

        attn_weight = F.softmax(attn_weight.reshape([bsz, T, -1]), axis=-1)
        attn_weight = attn_weight.reshape([bsz, T, h, w, c]).transpose([0, 1, 4, 2, 3])
        attn_feat = paddle.sum(paddle.multiply(feat.unsqueeze(1), attn_weight),
                                (3, 4), keepdim=False)

        if self.pred_concat:
            hf_c = holistic_feat.shape[-1]
            holistic_feat = paddle.expand(holistic_feat, shape=[bsz, seq_len, hf_c])
            y = self.prediction(paddle.concat(
                (y, attn_feat.astype(y.dtype), holistic_feat.astype(y.dtype)), 2))
        else:
            y = self.prediction(attn_feat)
        if self.train_mode:
            y = self.pred_dropout(y)
        return y

    def forward_train(self, feat, out_enc, label, img_metas):
        valid_ratios = None
        if img_metas is not None and self.mask:
            valid_ratios = img_metas[-1]
        lab_embedding = self.embedding(label)
        out_enc = out_enc.unsqueeze(1).astype(lab_embedding.dtype)
        in_dec = paddle.concat((out_enc, lab_embedding), axis=1)
        out_dec = self._2d_attention(in_dec, feat, out_enc, valid_ratios=valid_ratios)
        return out_dec[:, 1:, :]

    def forward_test(self, feat, out_enc, img_metas):
        valid_ratios = None
        if img_metas is not None and self.mask:
            valid_ratios = img_metas[-1]
        seq_len = self.max_seq_len
        bsz = feat.shape[0]
        start_token = self.embedding(
            paddle.full((bsz,), fill_value=self.start_idx, dtype="int64"))
        emb_dim = start_token.shape[1]
        start_token = paddle.expand(start_token.unsqueeze(1),
                                     shape=[bsz, seq_len, emb_dim])
        out_enc = out_enc.unsqueeze(1)
        decoder_input = paddle.concat((out_enc, start_token), axis=1)

        outputs = []
        for i in range(1, seq_len + 1):
            decoder_output = self._2d_attention(
                decoder_input, feat, out_enc, valid_ratios=valid_ratios)
            char_output = F.softmax(decoder_output[:, i, :], -1)
            outputs.append(char_output)
            max_idx = paddle.argmax(char_output, axis=1, keepdim=False)
            char_embedding = self.embedding(max_idx)
            if i < seq_len:
                decoder_input[:, i + 1, :] = char_embedding
        return paddle.stack(outputs, 1)

    def forward(self, feat, out_enc, label=None, img_metas=None, train_mode=True):
        self.train_mode = train_mode
        if train_mode:
            return self.forward_train(feat, out_enc, label, img_metas)
        return self.forward_test(feat, out_enc, img_metas)


class SARHead(nn.Layer):
    def __init__(self, in_channels, out_channels, enc_dim=512,
                 max_text_length=30, enc_bi_rnn=False, enc_drop_rnn=0.1,
                 enc_gru=False, dec_bi_rnn=False, dec_drop_rnn=0.0,
                 dec_gru=False, d_k=512, pred_dropout=0.1, pred_concat=True,
                 **kwargs):
        super().__init__()
        self.encoder = SAREncoder(enc_bi_rnn=enc_bi_rnn, enc_drop_rnn=enc_drop_rnn,
                                   enc_gru=enc_gru, d_model=in_channels, d_enc=enc_dim)
        self.decoder = ParallelSARDecoder(
            out_channels=out_channels, enc_bi_rnn=enc_bi_rnn,
            dec_bi_rnn=dec_bi_rnn, dec_drop_rnn=dec_drop_rnn, dec_gru=dec_gru,
            d_model=in_channels, d_enc=enc_dim, d_k=d_k,
            pred_dropout=pred_dropout, max_text_length=max_text_length,
            pred_concat=pred_concat)

    def forward(self, feat, targets=None):
        holistic_feat = self.encoder(feat, targets)
        if self.training:
            label = targets[0]
            return self.decoder(feat, holistic_feat, label, img_metas=targets)
        return self.decoder(feat, holistic_feat, label=None, img_metas=targets,
                            train_mode=False)
